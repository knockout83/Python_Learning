{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing Fundamentals in Python\n",
    "\n",
    "## CHAPTER 1\n",
    "\n",
    "\n",
    "### Introduction to Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 3), match='abc'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match('abc', 'abcdef')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 2), match='hi'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_regex = '\\w+'\n",
    "re.match(word_regex, 'hi there!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Split', 'on', 'spaces.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split('\\s+', 'Split on spaces.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\knock\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', 'there', '!']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(\"Hi there!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 3), match='abc'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match('abc', 'abcde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 3), match='abc'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search('abc', 'abcde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.match('cd', 'abcde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(2, 4), match='cd'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search('cd', 'abcde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Tokenization with regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_digits_and_words = ('(\\d+|\\w+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He', 'has', '11', 'cats']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(match_digits_and_words, 'He has 11 cats.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_str = 'match lowercase spaces nums like 12, but no commas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 35), match='match lowercase spaces nums like 12'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match('[a-z0-9 ]+', my_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charting Word Length with nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 0., 0., 0., 0., 2., 0., 3., 0., 1.]),\n",
       " array([1. , 1.8, 2.6, 3.4, 4.2, 5. , 5.8, 6.6, 7.4, 8.2, 9. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([1,5,5,7,7,7,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(\"This is a pretty cool tool!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lengths = [len(w) for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 0., 1., 0., 0., 0., 3., 0., 0., 1.]),\n",
       " array([1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. , 5.5, 6. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADhdJREFUeJzt3V2MXPV9h/HnG9t5KSFBileNZWw2VVClJCovXVEQUoSStIKAIFKJZKSSBKWyFEELaqQKuACFK7ghVUIU5AINpBSIeInc4DSlggi4gLB2zauDZCEqVlDZgQRw84Kc/nqx52K7jJmzuzM7+O/nI418Zua/c34jy4+Pj8/spqqQJLXlPZMeQJI0esZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQWsnteP169fX9PT0pHYvSYelnTt3/qKqpoatm1jcp6enmZ2dndTuJemwlOS/+qzztIwkNci4S1KDjLskNci4S1KDjLskNWho3JO8P8nPkjyZ5Nkk3xiw5n1J7kqyN8njSabHMawkqZ8+R+6/Az5TVScAJwJnJjl10ZqvAr+sqo8D3wSuG+2YkqSlGBr3mnegu7uuuy3+2XznAbd223cDn02SkU0pSVqSXufck6xJshvYBzxQVY8vWrIReAmgqg4CrwMfGeWgkqT+en1Ctap+D5yY5BjgviSfqqpnFiwZdJT+tp+8nWQrsBVg8+bNyxhXatv05fdPZL8vXnv2RPar8VnS1TJV9Svgp8CZi56aAzYBJFkLfBh4bcDXb6uqmaqamZoa+q0RJEnL1OdqmanuiJ0kHwA+B/x80bLtwJe77fOBB6vqbUfukqTV0ee0zAbg1iRrmP/L4AdV9aMk1wCzVbUduBn4fpK9zB+xbxnbxJKkoYbGvaqeAk4a8PhVC7Z/C3xxtKNJkpbLT6hKUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1aGjck2xK8lCSPUmeTXLpgDVnJHk9ye7udtV4xpUk9bG2x5qDwNeraleSo4GdSR6oqucWrXukqs4Z/YiSpKUaeuReVa9U1a5u+01gD7Bx3INJkpZvSefck0wDJwGPD3j6tCRPJvlxkk8e4uu3JplNMrt///4lDytJ6qd33JN8ELgHuKyq3lj09C7guKo6Afg28MNBr1FV26pqpqpmpqamljuzJGmIXnFPso75sN9eVfcufr6q3qiqA932DmBdkvUjnVSS1Fufq2UC3AzsqarrD7Hmo906kpzSve6roxxUktRfn6tlTgcuBJ5Osrt77EpgM0BV3QicD3wtyUHgN8CWqqoxzCtJ6mFo3KvqUSBD1twA3DCqoSRJK+MnVCWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQUPjnmRTkoeS7EnybJJLB6xJkm8l2ZvkqSQnj2dcSVIfa3usOQh8vap2JTka2Jnkgap6bsGas4Dju9ufAd/tfpUkTcDQI/eqeqWqdnXbbwJ7gI2Llp0H3FbzHgOOSbJh5NNKknpZ0jn3JNPAScDji57aCLy04P4cb/8LQJK0SvqclgEgyQeBe4DLquqNxU8P+JIa8Bpbga0AmzdvXsKY/9/05fcv+2tX6sVrz57YviWpr15H7knWMR/226vq3gFL5oBNC+4fC7y8eFFVbauqmaqamZqaWs68kqQe+lwtE+BmYE9VXX+IZduBL3VXzZwKvF5Vr4xwTknSEvQ5LXM6cCHwdJLd3WNXApsBqupGYAfweWAv8GvgotGPKknqa2jcq+pRBp9TX7imgItHNZQkaWX8hKokNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDhsY9yS1J9iV55hDPn5Hk9SS7u9tVox9TkrQUa3us+R5wA3DbO6x5pKrOGclEkqQVG3rkXlUPA6+twiySpBEZ1Tn305I8meTHST55qEVJtiaZTTK7f//+Ee1akrTYKOK+Cziuqk4Avg388FALq2pbVc1U1czU1NQIdi1JGmTFca+qN6rqQLe9A1iXZP2KJ5MkLduK457ko0nSbZ/SvearK31dSdLyDb1aJskdwBnA+iRzwNXAOoCquhE4H/hakoPAb4AtVVVjm1iSNNTQuFfVBUOev4H5SyUlSe8SfkJVkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkhpk3CWpQcZdkho0NO5JbkmyL8kzh3g+Sb6VZG+Sp5KcPPoxJUlL0efI/XvAme/w/FnA8d1tK/DdlY8lSVqJoXGvqoeB195hyXnAbTXvMeCYJBtGNaAkaelGcc59I/DSgvtz3WOSpAlZO4LXyIDHauDCZCvzp27YvHnzCHZ95Ji+/P6J7fvFa8+e2L6lcWn9z9QojtzngE0L7h8LvDxoYVVtq6qZqpqZmpoawa4lSYOMIu7bgS91V82cCrxeVa+M4HUlScs09LRMkjuAM4D1SeaAq4F1AFV1I7AD+DywF/g1cNG4hpUk9TM07lV1wZDnC7h4ZBNJklbMT6hKUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1qFfck5yZ5Pkke5NcPuD5ryTZn2R3d/vr0Y8qSepr7bAFSdYA3wH+HJgDnkiyvaqeW7T0rqq6ZAwzSpKWqM+R+ynA3qp6oareAu4EzhvvWJKklegT943ASwvuz3WPLfaXSZ5KcneSTYNeKMnWJLNJZvfv37+McSVJffSJewY8Vovu/yswXVV/AvwHcOugF6qqbVU1U1UzU1NTS5tUktRbn7jPAQuPxI8FXl64oKperarfdXf/EfjT0YwnSVqOPnF/Ajg+yceSvBfYAmxfuCDJhgV3zwX2jG5ESdJSDb1apqoOJrkE+AmwBrilqp5Ncg0wW1Xbgb9Nci5wEHgN+MoYZ5YkDTE07gBVtQPYseixqxZsXwFcMdrRJEnL5SdUJalBxl2SGmTcJalBxl2SGmTcJalBxl2SGmTcJalBxl2SGmTcJalBxl2SGmTcJalBxl2SGmTcJalBxl2SGmTcJalBxl2SGmTcJalBxl2SGmTcJalBxl2SGmTcJalBxl2SGmTcJalBxl2SGmTcJalBveKe5MwkzyfZm+TyAc+/L8ld3fOPJ5ke9aCSpP6Gxj3JGuA7wFnAJ4ALknxi0bKvAr+sqo8D3wSuG/WgkqT++hy5nwLsraoXquot4E7gvEVrzgNu7bbvBj6bJKMbU5K0FH3ivhF4acH9ue6xgWuq6iDwOvCRUQwoSVq6tT3WDDoCr2WsIclWYGt390CS53vsf5D1wC+W+bUrksmdcPI9Hxkm8p4n+HsMR+Dvc65b0Xs+rs+iPnGfAzYtuH8s8PIh1swlWQt8GHht8QtV1TZgW5/B3kmS2aqaWenrHE58z0cG3/ORYTXec5/TMk8Axyf5WJL3AluA7YvWbAe+3G2fDzxYVW87cpckrY6hR+5VdTDJJcBPgDXALVX1bJJrgNmq2g7cDHw/yV7mj9i3jHNoSdI763NahqraAexY9NhVC7Z/C3xxtKO9oxWf2jkM+Z6PDL7nI8PY33M8eyJJ7fHbD0hSgw6ruCe5Jcm+JM9MepbVkmRTkoeS7EnybJJLJz3TuCV5f5KfJXmye8/fmPRMqyHJmiT/meRHk55ltSR5McnTSXYnmZ30POOW5Jgkdyf5efdn+rSx7etwOi2T5NPAAeC2qvrUpOdZDUk2ABuqaleSo4GdwBeq6rkJjzY23aebj6qqA0nWAY8Cl1bVYxMebayS/B0wA3yoqs6Z9DyrIcmLwExVHRHXuSe5FXikqm7qrj78g6r61Tj2dVgduVfVwwy4fr5lVfVKVe3qtt8E9vD2Twg3peYd6O6u626Hz1HIMiQ5FjgbuGnSs2g8knwI+DTzVxdSVW+NK+xwmMX9SNd9t82TgMcnO8n4dacodgP7gAeqqvX3/A/A3wP/O+lBVlkB/55kZ/cJ9pb9EbAf+Kfu9NtNSY4a186M+2EiyQeBe4DLquqNSc8zblX1+6o6kflPRJ+SpNnTcEnOAfZV1c5JzzIBp1fVycx/19mLu1OvrVoLnAx8t6pOAv4HeNu3UB8V434Y6M473wPcXlX3Tnqe1dT9s/WnwJkTHmWcTgfO7c4/3wl8Jsk/T3ak1VFVL3e/7gPuY/670LZqDphb8K/Qu5mP/VgY93e57j8Xbwb2VNX1k55nNSSZSnJMt/0B4HPAzyc71fhU1RVVdWxVTTP/6e4Hq+qvJjzW2CU5qrtIgO70xF8AzV4JV1X/DbyU5I+7hz4LjO3CiF6fUH23SHIHcAawPskccHVV3TzZqcbudOBC4OnuHDTAld2nhlu1Abi1+0Ex7wF+UFVHzOWBR5A/BO7rfvTDWuBfqurfJjvS2P0NcHt3pcwLwEXj2tFhdSmkJKkfT8tIUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ16P8AUSKJo7DsGIIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(word_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHAPTER 2\n",
    "\n",
    "### Word counts with bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'The': 3,\n",
       "         'cat': 3,\n",
       "         'is': 2,\n",
       "         'in': 1,\n",
       "         'the': 3,\n",
       "         'box': 3,\n",
       "         '.': 3,\n",
       "         'likes': 1,\n",
       "         'over': 1})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(word_tokenize(\"\"\"The cat is in the box. The cat likes the box. The box is over the cat.\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\knock\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"The cat is in the box. The cat likes the box. The box is over the cat.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'cat', 'is', 'in', 'the', 'box', 'the', 'cat', 'likes', 'the', 'box', 'the', 'box', 'is', 'over', 'the', 'cat']\n"
     ]
    }
   ],
   "source": [
    "tokens = [w for w in word_tokenize(text.lower()) if w.isalpha()] # only returns alphabetic strings\n",
    "# take each token from the word_tokenize output of the lower case text if it contains only alphabetical characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_stops = [t for t in tokens if t not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cat', 3), ('box', 3)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(no_stops).most_common(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intoduction to gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_documents = ['The movie was about a spaceship and aliens.',\n",
    "                'I really liked the movie!',\n",
    "               'Awesome action scenes, but boring characters.',\n",
    "               'The movie was awful! I hate alien films.',\n",
    "               'Space is cool! I liked the movie.',\n",
    "               'More space films, please!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_docs = [word_tokenize(doc.lower()) for doc in my_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(tokenized_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 0,\n",
       " 'a': 1,\n",
       " 'about': 2,\n",
       " 'aliens': 3,\n",
       " 'and': 4,\n",
       " 'movie': 5,\n",
       " 'spaceship': 6,\n",
       " 'the': 7,\n",
       " 'was': 8,\n",
       " '!': 9,\n",
       " 'i': 10,\n",
       " 'liked': 11,\n",
       " 'really': 12,\n",
       " ',': 13,\n",
       " 'action': 14,\n",
       " 'awesome': 15,\n",
       " 'boring': 16,\n",
       " 'but': 17,\n",
       " 'characters': 18,\n",
       " 'scenes': 19,\n",
       " 'alien': 20,\n",
       " 'awful': 21,\n",
       " 'films': 22,\n",
       " 'hate': 23,\n",
       " 'cool': 24,\n",
       " 'is': 25,\n",
       " 'space': 26,\n",
       " 'more': 27,\n",
       " 'please': 28}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in tokenized_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)],\n",
       " [(5, 1), (7, 1), (9, 1), (10, 1), (11, 1), (12, 1)],\n",
       " [(0, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1)],\n",
       " [(0, 1),\n",
       "  (5, 1),\n",
       "  (7, 1),\n",
       "  (8, 1),\n",
       "  (9, 1),\n",
       "  (10, 1),\n",
       "  (20, 1),\n",
       "  (21, 1),\n",
       "  (22, 1),\n",
       "  (23, 1)],\n",
       " [(0, 1), (5, 1), (7, 1), (9, 1), (10, 1), (11, 1), (24, 1), (25, 1), (26, 1)],\n",
       " [(9, 1), (13, 1), (22, 1), (26, 1), (27, 1), (28, 1)]]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus # token id, token freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-idf with gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 0.1746298276735174),\n",
       " (7, 0.1746298276735174),\n",
       " (9, 0.1746298276735174),\n",
       " (10, 0.29853166221463673),\n",
       " (11, 0.47316148988815415),\n",
       " (12, 0.7716931521027908)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf-idf = term freuqncy - inverse document frequency\n",
    "# allows you to determine the most important words in each document\n",
    "# each corpus may have shared words beyond just stopwords\n",
    "# these words should be down-weighted in importance\n",
    "# example from astronomy: 'sky'\n",
    "# ensures most common words don't show up as key words\n",
    "# keeps document specific frequenct words weighted high\n",
    "\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "tfidf = TfidfModel(corpus)\n",
    "tfidf[corpus[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHAPTER 3\n",
    "\n",
    "### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\knock\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\knock\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\knock\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = '''In New York, I like to ride the Metro to visit MOMA and some restaurants rated well by Ruth Reichl.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'New',\n",
       " 'York',\n",
       " ',',\n",
       " 'I',\n",
       " 'like',\n",
       " 'to',\n",
       " 'ride',\n",
       " 'the',\n",
       " 'Metro',\n",
       " 'to',\n",
       " 'visit',\n",
       " 'MOMA',\n",
       " 'and',\n",
       " 'some',\n",
       " 'restaurants',\n",
       " 'rated',\n",
       " 'well',\n",
       " 'by',\n",
       " 'Ruth',\n",
       " 'Reichl',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sent = nltk.word_tokenize(sentence)\n",
    "tokenized_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('In', 'IN'),\n",
       " ('New', 'NNP'),\n",
       " ('York', 'NNP'),\n",
       " (',', ','),\n",
       " ('I', 'PRP'),\n",
       " ('like', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('ride', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('Metro', 'NNP'),\n",
       " ('to', 'TO'),\n",
       " ('visit', 'VB'),\n",
       " ('MOMA', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('some', 'DT'),\n",
       " ('restaurants', 'NNS'),\n",
       " ('rated', 'VBN'),\n",
       " ('well', 'RB'),\n",
       " ('by', 'IN'),\n",
       " ('Ruth', 'NNP'),\n",
       " ('Reichl', 'NNP'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sent = nltk.pos_tag(tokenized_sent)\n",
    "tagged_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('In', 'IN'), ('New', 'NNP'), ('York', 'NNP')]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sent[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  In/IN\n",
      "  (GPE New/NNP York/NNP)\n",
      "  ,/,\n",
      "  I/PRP\n",
      "  like/VBP\n",
      "  to/TO\n",
      "  ride/VB\n",
      "  the/DT\n",
      "  (ORGANIZATION Metro/NNP)\n",
      "  to/TO\n",
      "  visit/VB\n",
      "  (ORGANIZATION MOMA/NNP)\n",
      "  and/CC\n",
      "  some/DT\n",
      "  restaurants/NNS\n",
      "  rated/VBN\n",
      "  well/RB\n",
      "  by/IN\n",
      "  (PERSON Ruth/NNP Reichl/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "print(nltk.ne_chunk(tagged_sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy # this is a bitch to install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.pipes.EntityRecognizer at 0x24690609ee8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"\"\"Berlin is the capital of Germany; and the residence of Chancellor Angela Merkel.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Berlin, Germany, Angela Merkel)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berlin GPE\n"
     ]
    }
   ],
   "source": [
    "print(doc.ents[0], doc.ents[0].label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilingual NER with Polyglot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# polyglot is unstable on Windows and requires some shenanigans to install so I'll come back to it later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying fake news using supervised learning with NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supervised learning with NLP\n",
    "\n",
    "## Need to use language instead of geometric features\n",
    "## scikit-learn: Powerful open-source library\n",
    "## How to create supervised learning data from text?\n",
    "#### Use bag-of-words models or tf-idf as features\n",
    "\n",
    "# Supervised learning steps\n",
    "\n",
    "## Collect and preprocess our data\n",
    "## Determine a label (e.g. movie genre)\n",
    "## Split data into trianing and test sets\n",
    "## Extract features from the text to help predict the label\n",
    "#### Bag-of-words vector built into scikit-learn\n",
    "## Evaluate trained model using the test set\n",
    "\n",
    "# Ideas for Alpha data\n",
    "\n",
    "## Choose a component\n",
    "## Grab level 2 data where that component is labelled\n",
    "## Label this with 1 in response variable\n",
    "## Grab level 2 data where that component is labelled differently\n",
    "## Label this with 0 in response variable\n",
    "## Split data into trianing and test sets\n",
    "## Extract features from Level 2 text\n",
    "## Evaluate trained model with test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building word count vectors with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = ...# load data into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = df['Sci-Fi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(df['plot'], y, test_siize = 0.33, random_state = 53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_vectorizer = CountVectorizer(stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_train = count_vectorizer.fit_transform(X_train.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_test = count_vectorizer.transform(X_test.Values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing a classification model with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Model\n",
    "## Commonly used for testing NLP classification problems\n",
    "## Basis in probability\n",
    "\n",
    "# Given a particular piece of data, how likely is a particular outcome?\n",
    "## If the plot has a spaceship, how likely is it to be sci-fi?\n",
    "## Given a spaceship and and alien, how likely now is it sci-fi?\n",
    "\n",
    "# Each word from CountVectorizer acts as a feature\n",
    "\n",
    "# Naive Bayes: Simple and effective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nb_classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nb_classifier.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred = nb_classifier.predict(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics.accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics.confusion_matrix(y_test, pred, labels = [0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple NLP, Complex Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
